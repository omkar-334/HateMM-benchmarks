{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_paths = {\n",
    "    \"nonhate\": \"transcripts/transcriptions_OWN_NON_HATE_VIDEOS.csv\",\n",
    "    \"explicithate\": \"transcripts/transcriptions_OWN_EXPLICIT_HATE_VIDEOS.csv\",\n",
    "    \"implicithate\": \"transcripts/transcriptions_OWN_IMPLICIT_HATE_VIDEOS.csv\"\n",
    "}\n",
    "\n",
    "dfs = []\n",
    "for label, path in file_paths.items():\n",
    "    df = pd.read_csv(path)\n",
    "    df[\"label\"] = label\n",
    "    dfs.append(df)\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "df = df.drop(columns=[\"file_name\"])\n",
    "\n",
    "# Save to CSV if needed\n",
    "df.to_csv(\"transcripts/all_transcriptions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "def moderate_df(df, text_column=\"Transcription\", batch_size=32, only_na=True):\n",
    "    # Select rows to process (only NA values if only_na=True)\n",
    "    df_to_process = df[df[\"prediction\"].isna()] if only_na else df\n",
    "\n",
    "    for i in range(0, len(df_to_process), batch_size):\n",
    "        print(i, end=\"-\")\n",
    "        batch = df_to_process.iloc[i : i + batch_size]  # Select batch\n",
    "        texts = batch[text_column].tolist()  # Extract text column\n",
    "\n",
    "        try:\n",
    "            response = openai.moderations.create(input=texts)\n",
    "            results = response.model_dump()[\"results\"]\n",
    "            hateflags = [i[\"categories\"][\"hate\"] for i in results]\n",
    "\n",
    "            # Assign predictions directly using df.at\n",
    "            for idx, flag in zip(batch.index, hateflags):\n",
    "                df.at[idx, \"prediction\"] = flag\n",
    "\n",
    "            for idx, result in zip(batch.index, results):\n",
    "                df.at[idx, \"result\"] = result\n",
    "\n",
    "            time.sleep(2)  # Respect API rate limits\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            time.sleep(10)\n",
    "            continue\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-Incompatible indexer with Series\n",
      "32-64-96-128-160-192-224-256-288-320-352-384-416-448-480-512-544-576-608-640-672-704-736-768-800-832-864-896-928-960-992-1024-1056-1088-1120-1152-1184-1216-1248-1280-1312-1344-1376-1408-1440-1472-1504-1536-1568-1600-1632-1664-1696-1728-1760-1792-1824-1856-1888-1920-1952-1984-"
     ]
    }
   ],
   "source": [
    "df.loc[df[\"Transcription\"].isna(), \"prediction\"] = False\n",
    "mdf = moderate_df(df, text_column=\"Transcription\", batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nonhate prediction\n",
      "False    1000\n",
      "Name: count, dtype: int64\n",
      "explicithate prediction\n",
      "False    480\n",
      "True      20\n",
      "Name: count, dtype: int64\n",
      "implicithate prediction\n",
      "False    503\n",
      "True       6\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# print each with printing label also\n",
    "# read the pickle file first\n",
    "import pickle\n",
    "\n",
    "# with open(\"moderated_df.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(mdf, f)\n",
    "# read the pickle file first\n",
    "with open(\"moderated_df.pkl\", \"rb\") as f:\n",
    "    mdf = pickle.load(f)\n",
    "print(\"nonhate\", mdf[mdf[\"label\"] == \"nonhate\"].prediction.value_counts())\n",
    "print(\"explicithate\", mdf[mdf[\"label\"] == \"explicithate\"].prediction.value_counts())\n",
    "print(\"implicithate\", mdf[mdf[\"label\"] == \"implicithate\"].prediction.value_counts())\n",
    "\n",
    "# mdf[mdf['label']=='nonhate'].prediction.value_counts(), mdf[mdf[\"label\"] == \"explicithate\"].prediction.value_counts(), mdf[mdf[\"label\"] == \"implicithate\"].prediction.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"moderated_df.pkl\", \"wb\") as f:\n",
    "    pickle.dump(mdf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://claude.ai/chat/1e69b599-0fae-4419-9b1b-2e7be667875b\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"hate_speech_annotations_highkappa.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
