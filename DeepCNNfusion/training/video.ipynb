{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EA4bv4TaGrtL"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ[\"KAGGLE_KEY\"] = userdata.get('KAGGLE_KEY')\n",
        "os.environ[\"KAGGLE_USERNAME\"] = userdata.get('KAGGLE_USERNAME')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4l78SLKBJW3v"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle deepface numpy pandas opencv-python tensorflow scikit-learn -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dodLJo3DHG4M",
        "outputId": "cdb00c70-a249-4f61-a354-e8357479d6f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/msambare/fer2013\n",
            "License(s): DbCL-1.0\n",
            "Downloading fer2013.zip to /content\n",
            " 93% 56.0M/60.3M [00:00<00:00, 164MB/s]\n",
            "100% 60.3M/60.3M [00:00<00:00, 172MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d msambare/fer2013"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sYC4MzxCH4wi"
      },
      "outputs": [],
      "source": [
        "!mkdir -p video_data\n",
        "!unzip fer2013.zip -d video_data > /dev/null 2>&1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OrPSZFpwIgWv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "base_dir = 'video_data'\n",
        "\n",
        "def create_df(base_dir, subfolder):\n",
        "  data = []\n",
        "  subfolder = os.path.join(base_dir, subfolder)\n",
        "  for class_folder in os.listdir(subfolder):\n",
        "      class_path = os.path.join(subfolder, class_folder)\n",
        "      if os.path.isdir(class_path):\n",
        "          for image in os.listdir(class_path):\n",
        "              if image.endswith('.jpg'):\n",
        "                  image_path = os.path.join(class_path, image)\n",
        "                  data.append([class_folder, image_path])\n",
        "  df = pd.DataFrame(data, columns=['class', 'filepath'])\n",
        "  return df\n",
        "\n",
        "train_df = create_df(base_dir, 'train')\n",
        "test_df = create_df(base_dir, 'test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GmkpFLT8erDP"
      },
      "outputs": [],
      "source": [
        "def encode_and_bind(original_dataframe, feature_to_encode):\n",
        "    dummies = pd.get_dummies(original_dataframe[[feature_to_encode]])\n",
        "    res = pd.concat([original_dataframe, dummies], axis=1)\n",
        "    res = res.drop([feature_to_encode], axis=1)\n",
        "    return(res)\n",
        "\n",
        "train_df = encode_and_bind(train_df, 'class')\n",
        "test_df = encode_and_bind(test_df, 'class')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKt5c69MHnXG"
      },
      "source": [
        "Video Preprocessing  \n",
        "It is not needed for this FER-2013 dataset, since it is already in required format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVDUjN6yME2T"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def load_image(path):\n",
        "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "    if img is not None:\n",
        "        img = img.astype('float32') / 255.0\n",
        "        return img\n",
        "    return None\n",
        "\n",
        "train_df['image'] = train_df['filepath'].apply(load_image)\n",
        "test_df['image'] = test_df['filepath'].apply(load_image)\n",
        "\n",
        "test_df, val_df = train_test_split(test_df, test_size=0.5, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYbl3kpbNBel"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "\n",
        "class_cols = [i for i in train_df.columns if i.startswith('class')]\n",
        "\n",
        "class FERDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.images = np.stack(df['image'].values)\n",
        "        self.images = self.images.reshape(-1, 48, 48)  # Shape: (48, 48), no extra channel dimension\n",
        "        self.labels = df[class_cols].values.argmax(axis=1).astype('int64')\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Convert to a PyTorch tensor and add the channel dimension (1, 48, 48)\n",
        "        image = torch.FloatTensor(self.images[idx]).unsqueeze(0)  # Adds channel dimension\n",
        "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        return image, label\n",
        "\n",
        "\n",
        "train_dataset = FERDataset(train_df)\n",
        "test_dataset = FERDataset(test_df)\n",
        "val_dataset = FERDataset(val_df)\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csNPhKhiHatW"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "from models import ImageNet\n",
        "\n",
        "class EmotionTrainer:\n",
        "    def __init__(\n",
        "        self,\n",
        "        model,\n",
        "        train_loader,\n",
        "        val_loader,\n",
        "        optimizer,\n",
        "        criterion=nn.CrossEntropyLoss(),\n",
        "        device='cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    ):\n",
        "        self.model = model.to(device)\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        self.device = device\n",
        "        self.history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
        "\n",
        "    def train_epoch(self):\n",
        "        self.model.train()\n",
        "        total_loss = 0\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "\n",
        "        # Progress bar for training\n",
        "        pbar = tqdm(self.train_loader, desc='Training')\n",
        "\n",
        "        for batch_idx, (images, labels) in enumerate(pbar):\n",
        "            images, labels = images.to(self.device), labels.to(self.device)\n",
        "\n",
        "            # Zero the gradients\n",
        "            self.optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = self.model(images)\n",
        "            loss = self.criterion(outputs, labels)\n",
        "\n",
        "            # Backward pass and optimize\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            # Track metrics\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "            # Update progress bar\n",
        "            pbar.set_postfix({'loss': loss.item()})\n",
        "\n",
        "        # Calculate epoch metrics\n",
        "        epoch_loss = total_loss / len(self.train_loader)\n",
        "        epoch_acc = accuracy_score(all_labels, all_preds)\n",
        "\n",
        "        return epoch_loss, epoch_acc\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def validate(self):\n",
        "        self.model.eval()\n",
        "        total_loss = 0\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "\n",
        "        for images, labels in tqdm(self.val_loader, desc='Validation'):\n",
        "            images, labels = images.to(self.device), labels.to(self.device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = self.model(images)\n",
        "            loss = self.criterion(outputs, labels)\n",
        "\n",
        "            # Track metrics\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        # Calculate validation metrics\n",
        "        val_loss = total_loss / len(self.val_loader)\n",
        "        val_acc = accuracy_score(all_labels, all_preds)\n",
        "\n",
        "        # Print detailed classification report\n",
        "        print(\"\\nClassification Report:\")\n",
        "        print(classification_report(all_labels, all_preds))\n",
        "\n",
        "        return val_loss, val_acc\n",
        "\n",
        "    def train(self, num_epochs=133, save_best=True):\n",
        "        best_val_loss = float('inf')\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "\n",
        "            # Train and validate\n",
        "            train_loss, train_acc = self.train_epoch()\n",
        "            val_loss, val_acc = self.validate()\n",
        "\n",
        "            # Update history\n",
        "            self.history['train_loss'].append(train_loss)\n",
        "            self.history['val_loss'].append(val_loss)\n",
        "            self.history['train_acc'].append(train_acc)\n",
        "            self.history['val_acc'].append(val_acc)\n",
        "\n",
        "            # Print epoch summary\n",
        "            print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
        "            print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "            # Save best model\n",
        "            if save_best and val_loss < best_val_loss:\n",
        "                best_val_loss = val_loss\n",
        "                torch.save(self.model.state_dict(), 'best_model.pth')\n",
        "                print(\"Saved best model!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sf2ZGF9Vd4at",
        "outputId": "bfbac460-22ed-4921-b1f4-ec7744ca24c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/13\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 898/898 [08:43<00:00,  1.72it/s, loss=1.22]\n",
            "Validation: 100%|██████████| 113/113 [00:22<00:00,  5.13it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.41      0.04      0.08       494\n",
            "           1       0.00      0.00      0.00        60\n",
            "           2       0.25      0.05      0.09       525\n",
            "           3       0.45      0.72      0.55       869\n",
            "           4       0.35      0.24      0.29       610\n",
            "           5       0.26      0.47      0.34       623\n",
            "           6       0.47      0.58      0.52       408\n",
            "\n",
            "    accuracy                           0.38      3589\n",
            "   macro avg       0.31      0.30      0.27      3589\n",
            "weighted avg       0.36      0.38      0.32      3589\n",
            "\n",
            "Train Loss: 1.7433 | Train Acc: 0.2980\n",
            "Val Loss: 1.5874 | Val Acc: 0.3767\n",
            "Saved best model!\n",
            "\n",
            "Epoch 2/13\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 898/898 [08:35<00:00,  1.74it/s, loss=1.27]\n",
            "Validation: 100%|██████████| 113/113 [00:22<00:00,  5.12it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.12      0.19       494\n",
            "           1       0.00      0.00      0.00        60\n",
            "           2       0.31      0.05      0.08       525\n",
            "           3       0.54      0.84      0.66       869\n",
            "           4       0.34      0.63      0.44       610\n",
            "           5       0.34      0.26      0.30       623\n",
            "           6       0.59      0.61      0.60       408\n",
            "\n",
            "    accuracy                           0.45      3589\n",
            "   macro avg       0.36      0.36      0.33      3589\n",
            "weighted avg       0.42      0.45      0.39      3589\n",
            "\n",
            "Train Loss: 1.5217 | Train Acc: 0.4101\n",
            "Val Loss: 1.3984 | Val Acc: 0.4497\n",
            "Saved best model!\n",
            "\n",
            "Epoch 3/13\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 898/898 [08:33<00:00,  1.75it/s, loss=1.29]\n",
            "Validation: 100%|██████████| 113/113 [00:22<00:00,  5.10it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.43      0.26      0.33       494\n",
            "           1       0.00      0.00      0.00        60\n",
            "           2       0.38      0.16      0.22       525\n",
            "           3       0.65      0.80      0.72       869\n",
            "           4       0.38      0.64      0.48       610\n",
            "           5       0.38      0.39      0.38       623\n",
            "           6       0.67      0.55      0.61       408\n",
            "\n",
            "    accuracy                           0.49      3589\n",
            "   macro avg       0.41      0.40      0.39      3589\n",
            "weighted avg       0.48      0.49      0.47      3589\n",
            "\n",
            "Train Loss: 1.4172 | Train Acc: 0.4552\n",
            "Val Loss: 1.3123 | Val Acc: 0.4921\n",
            "Saved best model!\n",
            "\n",
            "Epoch 4/13\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 898/898 [08:34<00:00,  1.75it/s, loss=1.93]\n",
            "Validation: 100%|██████████| 113/113 [00:22<00:00,  5.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.37      0.41       494\n",
            "           1       1.00      0.03      0.06        60\n",
            "           2       0.42      0.14      0.21       525\n",
            "           3       0.68      0.77      0.72       869\n",
            "           4       0.40      0.60      0.48       610\n",
            "           5       0.43      0.32      0.37       623\n",
            "           6       0.50      0.77      0.61       408\n",
            "\n",
            "    accuracy                           0.50      3589\n",
            "   macro avg       0.55      0.43      0.41      3589\n",
            "weighted avg       0.50      0.50      0.48      3589\n",
            "\n",
            "Train Loss: 1.3524 | Train Acc: 0.4811\n",
            "Val Loss: 1.2860 | Val Acc: 0.5049\n",
            "Saved best model!\n",
            "\n",
            "Epoch 5/13\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 898/898 [08:34<00:00,  1.74it/s, loss=1.47]\n",
            "Validation: 100%|██████████| 113/113 [00:22<00:00,  5.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.36      0.40       494\n",
            "           1       0.53      0.15      0.23        60\n",
            "           2       0.42      0.16      0.23       525\n",
            "           3       0.74      0.75      0.75       869\n",
            "           4       0.44      0.58      0.50       610\n",
            "           5       0.37      0.52      0.43       623\n",
            "           6       0.67      0.67      0.67       408\n",
            "\n",
            "    accuracy                           0.52      3589\n",
            "   macro avg       0.52      0.46      0.46      3589\n",
            "weighted avg       0.53      0.52      0.51      3589\n",
            "\n",
            "Train Loss: 1.3128 | Train Acc: 0.4960\n",
            "Val Loss: 1.2347 | Val Acc: 0.5241\n",
            "Saved best model!\n",
            "\n",
            "Epoch 6/13\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 898/898 [08:35<00:00,  1.74it/s, loss=1.24]\n",
            "Validation: 100%|██████████| 113/113 [00:22<00:00,  5.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.33      0.41       494\n",
            "           1       0.50      0.08      0.14        60\n",
            "           2       0.38      0.22      0.28       525\n",
            "           3       0.74      0.77      0.76       869\n",
            "           4       0.48      0.54      0.51       610\n",
            "           5       0.37      0.54      0.44       623\n",
            "           6       0.63      0.73      0.68       408\n",
            "\n",
            "    accuracy                           0.53      3589\n",
            "   macro avg       0.52      0.46      0.46      3589\n",
            "weighted avg       0.53      0.53      0.52      3589\n",
            "\n",
            "Train Loss: 1.2808 | Train Acc: 0.5131\n",
            "Val Loss: 1.1970 | Val Acc: 0.5341\n",
            "Saved best model!\n",
            "\n",
            "Epoch 7/13\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  72%|███████▏  | 649/898 [06:12<02:57,  1.41it/s, loss=1.36]"
          ]
        }
      ],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "model = ImageNet()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "\n",
        "trainer = EmotionTrainer(\n",
        "    model=model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    optimizer = optimizer,\n",
        ")\n",
        "\n",
        "trainer.train(num_epochs=113)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [
        "csNPhKhiHatW"
      ],
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
